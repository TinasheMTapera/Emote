---
title: "Frequency Domain ML w/ Ensembling"
output: html_notebook
---

Here we implement ML in the frequency domain, but ensemble the results of our separate models across each 5 minute window.

```{r, include=FALSE}
library(tidyverse, quietly = T)
library(caret, quietly = T)
library(DMwR, quietly = T)
library(ROSE, quietly = T)
library(viridis, quietly = T)
library(DAAG, quietly = T)
set.seed(4)
```


```{r, include=FALSE}
#save participants who qualify with both episode and control
pp = c(201, 202, 207, 214, 215, 217, 218, 219, 226, 228)
```

```{r}
features_output = read.csv("~/GDriveDocs/Quantitative Psychology & Statistics Lab/Emote/DataOutputs/data_out_20181113.csv")%>%
  as.tibble()
```

```{r, include=FALSE, echo=FALSE}
# Here we set the train and test set
mydat = features_output%>%
  filter(ID %in% pp)%>%
  filter(!(Stress > 4 & Y == "Control"))%>% #filter high stress
  select(ID, Y, Avg_niHR:LFHF_6)%>%
  rename(Class = Y)%>%
  mutate(Class = as.factor(Class))%>%
  mutate_at(., .funs = funs(ifelse(. > 3630, 3630, 
                                   ifelse(. < 80, 80, .))),
            .vars = vars(matches("^HF_.*")))%>%
  mutate_at(., .funs = funs(ifelse(. > 1010, 101,
                                   ifelse(. < 190, 190, .))), 
            .vars = vars(matches("^LF_.*")))%>%
  mutate_at(., .funs = funs(ifelse(. > 12, 12,
                                   ifelse(. < 1, 1, .))), 
            .vars = vars(matches("LFHF_.*")))

#set up a list of unnamed data sets based on variable names
# loop through list and select variables dynamically
# partition at 70%
# downsample training set

datasets = list()

for(n in 1:6){
  
  temp_dat = mydat%>%
    select(ID, Class, Class, Avg_niHR:Avg_HR, contains(as.character(n)))%>%
    filter(complete.cases(.))%>%
    group_by(ID, Class)%>%
    nest()%>%
    mutate(rows = purrr::map(data, nrow))%>%
    unnest(rows)%>%
    group_by(ID)%>%
    mutate(rows = min(rows))%>%
    ungroup()%>%
    mutate(samp = purrr::map2(data, rows, sample_n))%>%
    select(-data, -rows)%>%
    unnest(samp)%>%
    select(-ID)
    
  
   ind = createFolds(y = temp_dat$Class, k=4, list=TRUE, returnTrain = FALSE)
   
   datasets[[n]] = list(data = temp_dat, folds = ind)
    
}

#statistically significant diff variables
temp_dat = mydat%>%
  select(ID, Class, Avg_niHR, End_niHR, Avg_HR, HF_4, LF_3)%>%
  filter(complete.cases(.))%>%
  group_by(ID, Class)%>%
  nest()%>%
  mutate(rows = purrr::map(data, nrow))%>%
  unnest(rows)%>%
  group_by(ID)%>%
  mutate(rows = min(rows))%>%
  ungroup()%>%
  mutate(samp = purrr::map2(data, rows, sample_n))%>%
  select(-data, -rows)%>%
  unnest(samp)%>%
  select(-ID)

ind = createFolds(y = temp_dat$Class, k=4, list=TRUE, returnTrain = FALSE)

datasets[[7]] = list(data = temp_dat, folds = ind)
```

```{r, include=FALSE, echo=FALSE}
fitGLM = function(datalist){
  
  # use the list [dataset, folds] to run caret glm and
  # return a list [model fit results, predictions]
  
  summaries = list()
  predictions = list()
  
  for(fold in 1:4){
    
    model = train(Class ~ .,
            method = "glm",
            family = binomial,
            data = datalist$data[-datalist$folds[[fold]],])
    
    summaries[[fold]] = summary(model)%>%
      .$coefficients%>%
      data.frame()%>%
      as.tibble()%>%
      rownames_to_column(var = "Variable")%>%
      rename(P_Value = Pr...z..,
             Z_Value = z.value,
             Std_Error = Std..Error)%>%
      mutate(Significant = ifelse(P_Value < 0.05, "Significant", "Not Significant"),
             Fold = fold)
    
    predictions[[fold]] = predict(model, 
                                  newdata = datalist$data[datalist$folds[[fold]],],
                                  type = "raw")%>%
      data.frame(pred = ., 
                 obs = datalist$data[datalist$folds[[fold]],]$Class)
  }
  
  return(list(summaries = summaries, predictions = predictions))
  
}

fitRF = function(datalist){
  
  # use the list [dataset, folds] to run caret random forest and
  # return a list [model fit results, predictions]
  
  summaries = list()
  predictions = list()
  
  for(fold in 1:4){
    
    tc = trainControl("cv", 
                      number = 10, 
                      savePredictions=T, 
                      search = "random",
                      summaryFunction = twoClassSummary,
                      classProbs = T)
    model = train(Class~., 
                  data=datalist$data[-datalist$folds[[fold]],], 
                  method="rf", 
                  metric="ROC", 
                  tuneLength=15, 
                  trControl=tc)
  
  summaries[[fold]] = randomForest::importance(model$finalModel)%>%
    as.data.frame()%>%
    rownames_to_column("Variable")%>%
    arrange(MeanDecreaseGini)
  
  predictions[[fold]] = predict(model, 
      newdata = datalist$data[datalist$folds[[fold]],],
      type = "raw")%>%
      data.frame(pred = ., 
                 obs = datalist$data[datalist$folds[[fold]],]$Class)
  
  }
  
  return(list(summaries = summaries, predictions = predictions))
  
}
fitXG = function(datalist){
  
  # use the list [dataset, folds] to run caret xgboost and
  # return a list [model fit results, predictions]
  
  summaries = list()
  predictions = list()
  for(fold in 1:4){
    tc = trainControl("cv", 10, 
                        savePredictions=T, 
                        search = "random",
                        summaryFunction = twoClassSummary,
                        classProbs = T) 
      
    model = train(Class ~.,
                 method = "xgbTree",
                 data=datalist$data[-datalist$folds[[fold]],],
                 trControl = tc,
                 metric = "ROC",
                 tuneLength = 3)
    
    predictions[[fold]] = predict(model, 
        newdata = datalist$data[datalist$folds[[fold]],],
        type = "raw")%>%
        data.frame(pred = ., 
                   obs = datalist$data[datalist$folds[[fold]],]$Class)
    }
  
  return(list(summaries = summaries, predictions = predictions))
}
fitSVM = function(datalist){
  
  # use the list [dataset, folds] to run caret SVM and
  # return a list [model fit results, predictions]
  summaries = list()
  predictions = list()  
  for(fold in 1:4){
    tc = trainControl("cv", 15, 
                      savePredictions=T, 
                      summaryFunction = twoClassSummary,
                      classProbs = T,
                      search = "random")
    
    model = train(Class ~.,
                 method = "svmLinear",
                 data=datalist$data[-datalist$folds[[fold]],],
                 trControl = tc,
                 tuneLength = 3,
                 metric = "ROC")
    
    predictions[[fold]] = predict(model, 
        newdata = datalist$data[datalist$folds[[fold]],],
        type = "raw")%>%
        data.frame(pred = ., 
                   obs = datalist$data[datalist$folds[[fold]],]$Class)
  }
  
  return(list(summaries = summaries, predictions = predictions))
}

fitNN = function(datalist){
  
  # use the list [dataset, folds] to run caret NN and
  # return a list [model fit results, predictions]
  summaries = list()
  predictions = list() 
  
  for(fold in 1:4){
    
    tc = trainControl(method = 'cv', number = 50, 
                    classProbs = TRUE, 
                    summaryFunction = twoClassSummary, 
                    savePredictions = TRUE,
                    search = "random")
  
    model = train(Class ~.,
                 method = "nnet",
                 data=datalist$data[-datalist$folds[[fold]],],
                 trControl = tc,
                 tuneLength = 5,
                 metric = "ROC")
    
    predictions[[fold]] = predict(model, 
        newdata = datalist$data[datalist$folds[[fold]],],
        type = "raw")%>%
        data.frame(pred = ., 
                   obs = datalist$data[datalist$folds[[fold]],]$Class)
  }
  
  return(list(summaries = summaries, predictions = predictions))
  
}

ExtractConfusionMatrix = function(df){
  
  df%>%
    table()%>%
    confusionMatrix(positive = "Episode")%>%
    .$byClass%>%
    t()%>%
    as.tibble()%>%
    return()
}

EnsembleWindow = function(datalist_window){
  
  # A function to ensemble the results of multiple classifiers
  # Input: datalist_window, a list of confusion matrices with predictions for each model, with multiple folds
  
  models = names(datalist_window)
  nfolds = length(datalist_window[[models[1]]]$predictions)

  fold_results = vector("list", nfolds)
  # for each model, gather the predictions
  for(n in 1:nfolds){
    
    gathered_votes = sapply(datalist_window, function(x) return(x$predictions[n]))%>%
      sapply(., function(x) return(x$pred))%>%
      as.data.frame()%>%
      sjmisc::row_count(., count = "Episode", var="Episode")%>%
      sjmisc::row_count(., count = "Control", var="Control")%>%
      select(one_of(c("Episode", "Control")))%>%
      rownames_to_column()%>%
      gather(pred, value, -rowname)
    
    fold_results[[n]]$final = gathered_votes%>%
      group_by(rowname)%>% 
      top_n(value, n = 1)%>%
      arrange(as.numeric(rowname))%>%
      ungroup()%>%
      select(pred)
    
    fold_results[[n]]$final$obs = sapply(datalist_window, function(x) return(x$predictions[n]))%>%
      sapply(., function(x) return(x$obs))%>%
      .[,1]
    
  }
  
  fold_results%>%
    unlist(x = ., recursive = FALSE, use.names=FALSE)%>%
    return()
  
}
```

```{r, echo=FALSE, include=FALSE}
model_fits = list()

for(dataset in 1:length(datasets)){
  
  model_fits[[dataset]] = list(
    glm  = fitGLM(datasets[[dataset]]),
    rf = fitRF(datasets[[dataset]]),
    xgb = fitXG(datasets[[dataset]]),
    svm = fitSVM(datasets[[dataset]]),
    nn = fitNN(datasets[[dataset]])
  )
  
}
```

# Ensemble the results

```{r}
model_results = lapply(model_fits, EnsembleWindow)
```

The results:

```{r}

final_results = data.frame()
fold=1:4

for(win in 1:length(model_results)){
  
  final_results = model_results[[win]]%>%
    Map(cbind, ., fold=fold)%>%
    do.call(rbind,.)%>%
    group_by(fold)%>%
    nest()%>%
    mutate(result=lapply(data, ExtractConfusionMatrix))%>%
    select(-data)%>%
    unnest()%>%
    select(-fold)%>%
    summarise_all(funs(mean))%>%
    mutate(window=win)%>%
    rbind(final_results,.)
}

final_results%>%
  gather(key="key", value="value", -window)%>%
  mutate(window = as.factor(window))%>%
  ggplot(aes(x=key,y=value))+
  geom_bar(aes(fill=window), stat = "identity", position="dodge")+
  coord_flip()+
  theme_minimal()+
  labs(title = "Ensembled Prediction Results")+
  scale_fill_viridis(discrete=T)
```

