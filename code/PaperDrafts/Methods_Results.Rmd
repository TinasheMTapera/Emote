---
title: "Methods & Results Section"
output:
  bookdown::html_document2: null
  bookdown::word_document2:
    toc: false
bibliography: citations.bib
always_allow_html: yes
---

```{r packages and setup, include=FALSE, warning=FALSE}
suppressPackageStartupMessages(
  {
    library(tidyverse, quietly = TRUE)
    library(knitr, quietly = TRUE)
    library(DAAG, quietly = TRUE)
    library(here, quietly = TRUE)
    library(naniar, quietly = TRUE)
    library(kableExtra, quietly = TRUE)
    library(ggsignif, quietly = TRUE)
    library(viridis, quietly = TRUE)
    library(forcats, quietly = TRUE)
    library(caret, quietly = TRUE)
    library(ROSE, quietly = TRUE)
    library(e1071, quietly = TRUE)
    library(ModelMetrics, quietly = TRUE)
    library(scales, quietly = TRUE)
  }
)

p_format <- function(vec, thresh = 0.05, star1 = 0.05, star2 = 0.01, star3 = 0.001){
  
  vec2 = NULL
  vec2 <- sapply(vec, formatC)
  
  for(x in 1:length(vec)){
    if(vec[x] <= star3){
      vec2[x] = "< 0.001 ***"
    }
    else if(vec[x] <= star2){
      vec2[x] = "< 0.01 **"
    }
    else if(vec[x] <= star1){
      vec2[x] = "< 0.05 *"
    }
  }
  vec2
}

permutation_plot <- function(df, height = 1.2, tip = 0.1){
  
  n <- df %>%
    rowid_to_column() %>%
    group_by(variable) %>%
    arrange(-Mean) %>%
    slice(1) %>%
    pull(rowid)
  y_position <- df$Mean[n] * height
  
  plt  <- df %>% 
    mutate(Feature = variable) %>%
    {
      ggplot(., aes(x = Feature, y = Mean, fill = Group)) +
        geom_col(position = "dodge") +
        theme_minimal() +
        theme(axis.text.x = element_text(angle = 90, hjust = 1), text = element_text(size=15, family = "Times")) + 
        geom_signif(family = "Times", annotations = sapply(.$p.val[n], p_format),
                    xmin = seq(0.8, length.out = length(n)),
                    xmax = seq(1.2, length.out = length(n)),
                    y_position = y_position,
                    tip_length=tip
                    ) +
        scale_fill_viridis_d(labels = c("Control", "Episode"))
  }
  plt
}

set.seed(1342)
```

```{r load data, include=FALSE, warning=FALSE, message=FALSE}
# all initial surveys
all_surveys <- read_csv(here('data','Preprocessing_data_outputs', 'UpdatedSurveys_180713.csv')) %>%
  filter(complete.cases(.)) %>%
  mutate(Y = ifelse(EmotionalEatingEpisodes == 2, 'Control', 'Episode'))

# data used for frequency domain analysis
df_freq <- read_csv(here('data', 'Preprocessing_data_outputs', 'Paper', 'data_out_20181113.csv'))

# data used for time domain analysis
df_time <- read_csv(here('data', 'Preprocessing_data_outputs', 'Paper', 'data_out.csv'))
```
# Methods
Data analyses were carried out in `r R.version$version.string` and Python 2.7. In accordance with previous studies examining the relation between HRV and discrete eating episodes [@friesen_lin_schurman_andre_callum_2007; @harthoorn_dransfield_2007; @ranzenhofer2016], physiological data collected in the 30-minute period preceding the eating episode were examined. For each participant, the inter-beat interval (IBI) for each self-reported survey was selected, where surveys were either self-reported at the time of an eating episode, or pseudo-randomly triggered in the app. This resulted in an initial total of $n=$ `r all_surveys %>% filter(Y == "Episode") %>% nrow()` emotional eating episodes and $n=$ `r all_surveys %>% filter(Y == "Control") %>% nrow()` control episodes before cleaning the data.

Using the RHRV package [@R-RHRV], IBI data streams were filtered, interpolated, and artifacts were removed, using thresholds and parameters in compliance with normative reported values for heart rate variability features [@shaffer_ginsberg_2017]. Observations that did not meet normative criteria were removed. Consistent with existing research, features of heart rate variability were extracted from both the time and frequency domain to measure both the amount of variability and the amount of signal energy in the 30-minute period [@shaffer_ginsberg_2017; @Rubin:2016:TFC:3021319.3021332].
  
  The following heart rate variability features were extracted from the IBI streams for each observation in the time domain: *SDNN* (Standard Deviation of all filtered inter-beat intervals); *SDANN* (Standard Deviation of inter-beat intervals between all successive heartbeats); *SDNNIX* (Mean of the standard deviations of all the filtered inter-beat intervals for each 5 min segment of the IBI stream); *pNN50* (Percentage of successive inter-beat intervals that differ by more than 50 ms); *SDSD* (Standard Deviation of Successive Differences of inter-beat intervals); *rMSSD* (Root Mean Square of Successive Differences); *IRRR* (length of the interval determined by the first and the third quantile of the inter-beat interval); *MADRR* (Median of the Absolute values of the successive Differences between the inter-beat intervals); *TINN* (Triangular Interpolation of inter-beat interval histogram); and *HRVi* (Heart Rate Variability index) [@R-RHRV].
  
  *SDNN* reflects the power of the components responsible for variability in heart rhythm, while *SDANN*, *SDNNIX*, *pNN50*, *SDSD*, *rMSSD*, *IRRR*, and *MADRR* reflect different statistical aspects of the high frequency variation in heart rhythm. Finally, *TINN* and *HRVi* represent geometric measures calculated from the density distribution of inter-beat intervals [@R-RHRV].
  
  In the frequency domain, features extracted included the mean non-interpolated heart rate (*mean niHR*), the mean interpolated Heart Rate (*mean HR*), and the heart rate values at the start and end of the 30 minute window (*Start HR*, *End HR*). Additional frequency domain features were extracted from the 30 minute streams by applying a Fourier transform to the heart rate signal, resulting in a spectrogram of the heart rate in the low and high frequency ranges. To extract a sufficient amount of information from these spectograms and increase the variance of our data, the spectrogram was split into 5 minute windows, as has been done previously in studies using heart rate variability to predict event-level behavior [@Rubin:2016:TFC:3021319.3021332]. Mean features were extracted from each of these windows — the mean Low Frequency signal ($LF_1$, $LF_2$,… $LF_6$), the mean High Frequency signal ($HF_1$, $HF_2$,… $HF_6$), and the mean Low Frequency-High Frequency Ratio ($LFHF_1$, $LFHF_2$,… $LFHF_6$).
  
  In order to examine any differences between means of the features, and address the issue of group imbalance affecting statistical power, we conducted between-groups permutation T-tests with each variable in the time and frequency domain [@R-DAAG; @good2013permutation]. Then, using the CARET package [@R-caret], a Support Vector Machine with a polynomial kernel was implemented to predict episodes from controls. In order to address the group imbalance in this stage, all features were standardized, while controls were randomly downsampled and episodes were randomly upsampled using the ROSE package [@R-ROSE]. To evaluate model performance, models were tested using 4-fold cross validation, training models on 3/4 of the data and using the remaining data evaluate the model accuracy, specificity, and sensitivity.
  
# Results

## Missingness
```{r source-missingness, echo = FALSE}
df_time_nrow <- df_time %>% 
  # use params threshold = 250, windows = 2
  filter(threshold == 250 & winds == 2) %>%
  # remove high stress controls
  filter(!(Stress >= 5 & Y == "Control")) %>%
  select(-c(winds, threshold, index, when, Event, Stress, ID), Y, SDNN:HRVi) %>%
  group_by(Y) %>%
  count()

df_freq_nrow <- df_freq %>%
  # use params threshold = 100, windows = 2
  filter(threshold == 100 & winds == 2) %>%
  # remove high stress controls
  filter(!(Stress >= 5 & Y == "Control")) %>%
  select(-c(winds, threshold, index, when, Event, Stress, ID), Y, SDNN:HRVi) %>%
  group_by(Y) %>%
  count()
```


(ref:missingness-time) Completeness of Features in the Time Domain

(ref:missingness-freq) Completeness of Features in the Frequency Domain

(ref:missingness-tab) Number of Observations Extracted for Each Feature


  After cleaning the dataset of erroneous surveys (e.g. no usable IBI data; overlapping survey responses; control observations with high self-reported stress), and filtering IBI streams that did not meet filtering quality criteria for preprocessing, the data consisted of $n=$ `r df_time_nrow %>% filter(Y == "Episode") %>% pull(n)` emotional eating episodes and $n=$ `r df_time_nrow %>% filter(Y == "Control") %>% pull(n)` controls. Of these clean observations, HRV features were extracted from the IBI streams, although even with filtering, many IBI streams were too sparse to compute HRV features. Figures \@ref(fig:missingness-time) and \@ref(fig:missingness-freq) illustrate the completeness of data in the extracted time and frequency domain features, with table \@ref(tab:missingness-tab) showing the final number of observations used for analysis. Much of the data missing from the time domain is due to the fact that these features derived from SDNN and are dependent on having sufficient data in this feature.


```{r missingness-time, fig.width=9, fig.asp=1, echo = FALSE, fig.cap='(ref:missingness-time)'}
df_time %>% 
  # use params threshold = 250, windows = 2
  filter(threshold == 250 & winds == 2) %>%
  # remove high stress controls
  filter(!(Stress >= 5 & Y == "Control")) %>%
  select(-c(winds, threshold, index, when, Event, Stress, ID, Y), SDNN:HRVi) %>%
  vis_miss(.) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    text = element_text(size=15, family = "Times")
    )
```


```{r missingness-freq, fig.width=9, fig.asp=1, fig.cap='(ref:missingness-freq)', echo = FALSE}
df_freq %>% 
  # use params threshold = 100, windows = 2
  filter(threshold == 100 & winds == 2) %>%
  # remove high stress controls
  filter(!(Stress >= 5 & Y == "Control")) %>%
  select(-c(winds, threshold, index, when, Event, Stress, ID, Y)) %>%
  select(Avg_niHR:LFHF_6) %>%
  vis_miss(.) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    text = element_text(size=15, family = "Times")
    )
```

```{r missingness-tab, echo = FALSE, warning = FALSE, message = FALSE, results='asis'}
missingnesstable_time <- df_time %>% 
  # use params threshold = 250, windows = 2
  filter(threshold == 250 & winds == 2) %>%
  # remove high stress controls
  filter(!(Stress >= 5 & Y == "Control")) %>%
  select(-c(winds, threshold, index, when, Event, Stress, ID), Y, SDNN:HRVi) %>%
  group_by(Y) %>%
  summarise_all(funs(sum(!is.na(.)))) %>%
  t()

colnames(missingnesstable_time) <- missingnesstable_time[1,]
missingnesstable_time <- missingnesstable_time[-1,] %>%
  data.frame() %>%
  rownames_to_column(var = "Variable")

missingnesstable_freq <- df_freq %>% 
  # use params threshold = 250, windows = 2
  filter(threshold == 100 & winds == 2) %>%
  # remove high stress controls
  filter(!(Stress >= 5 & Y == "Control")) %>%
  # select frequency domain
  select(-c(winds, threshold, index, when, Event, Stress, ID)) %>%
  select(Y, Avg_niHR:LFHF_6) %>%
  group_by(Y) %>%
  summarise_all(funs(sum(!is.na(.)))) %>%
  t()

colnames(missingnesstable_freq) <- missingnesstable_freq[1,]
missingnesstable_freq <- missingnesstable_freq[-1,] %>%
  data.frame() %>%
  rownames_to_column(var = "Variable")

bind_rows(missingnesstable_time, missingnesstable_freq)%>%
  kable(caption = '(ref:missingness-tab)') %>%
  kable_styling() %>%
  kableExtra::group_rows("Heart Rate Variability", 1, 10) %>%
  kableExtra::group_rows("Heart Rate", 11, 14) %>%
  kableExtra::group_rows("High Frequency", 15, 20) %>%
  kableExtra::group_rows("Low Frequency", 21, 26) %>%
  kableExtra::group_rows("LF-HF Ratio", 27, 32)
```

## Comparison of Means

```{r source-tests, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE}
df_time_summaries <- df_time %>% 
  # use params threshold = 250, windows = 2
  filter(threshold == 250 & winds == 2) %>%
  # remove high stress controls
  filter(!(Stress >= 5 & Y == "Control")) %>%
  # select time domain
  select(-c(winds, threshold, index, when, Event, Stress, ID), Y, SDNN:HRVi) %>%
  # use summarise_at to create within variable summaries
  summarise_at(
    .funs = funs(
      
      # for each variable, count non-NA
      n = length(.[complete.cases(.)]),
      n.control = length(.[complete.cases(.) & Y == "Control"]),
      n.episode = length(.[complete.cases(.) & Y != "Control"]),
      
      # for each variable, calculate the mean, removing NA in each
      mean = mean(., na.rm = TRUE),
      mean.control = mean(.[Y == "Control"], na.rm = TRUE),
      mean.episode = mean(.[Y != "Control"], na.rm = TRUE),
      
      # for each variable, calculate the sd, removing NA in each
      sd = sd(., na.rm = TRUE),
      sd.control = sd(.[Y == "Control"], na.rm = TRUE),
      sd.episode = sd(.[Y != "Control"], na.rm = TRUE),
      
      # for each variable, run TwoT perm between control and episode, removing NA in each
      p.val = twotPermutation(.[Y == "Control" & !is.na(.)],
                              .[Y != "Control" & !is.na(.)],
                              nsim = 10000, plotit = F)
      ),
    .vars = vars(SDNN:HRVi)
    ) %>% 
  gather(key, value) %>%
  separate(key, c("variable", "statistic"), sep = "_")

df_freq_summaries <- df_freq %>% 
  # use params threshold = 250, windows = 2
  filter(threshold == 100 & winds == 2) %>%
  # remove high stress controls
  filter(!(Stress >= 5 & Y == "Control")) %>%
  # select frequency domain
  select(-c(winds, threshold, index, when, Event, Stress, ID)) %>%
  select(Y, Avg_niHR:LFHF_6) %>%
  
  # truncate frequency power bands
  mutate_at(., .funs = funs(ifelse(. > 3630, 3630, 
                                   ifelse(. < 80, 80, .))),
            .vars = vars(matches("^HF_.*")))%>%
  mutate_at(., .funs = funs(ifelse(. > 1010, 101,
                                   ifelse(. < 190, 190, .))), 
            .vars = vars(matches("^LF_.*")))%>%
  mutate_at(., .funs = funs(ifelse(. > 12, 12,
                                   ifelse(. < 1, 1, .))), 
            .vars = vars(matches("LFHF_.*"))) %>%
  
  # use summarise_at to create within variable summaries
  summarise_at(
    .funs = funs(
      
      # for each variable, count non-NA
      n = length(.[complete.cases(.)]),
      n.control = length(.[complete.cases(.) & Y == "Control"]),
      n.episode = length(.[complete.cases(.) & Y != "Control"]),
      
      # for each variable, calculate the mean, removing NA in each
      mean = mean(., na.rm = TRUE),
      mean.control = mean(.[Y == "Control"], na.rm = TRUE),
      mean.episode = mean(.[Y != "Control"], na.rm = TRUE),
      
      # for each variable, calculate the sd, removing NA in each
      sd = sd(., na.rm = TRUE),
      sd.control = sd(.[Y == "Control"], na.rm = TRUE),
      sd.episode = sd(.[Y != "Control"], na.rm = TRUE),
      
      # for each variable, run TwoT perm between control and episode, removing NA in each
      p.val = twotPermutation(.[Y == "Control" & !is.na(.)],
                              .[Y != "Control" & !is.na(.)],
                              nsim = 10000, plotit = F)
      ),
    .vars = vars(Avg_niHR:LFHF_6)
    ) %>% 
  gather(key, value) %>%
  separate(key, c("variable", "statistic"), sep = "_(?!.*_)")

```

(ref:timeSummary) Summary of Features in the Time Domain

The mean values for each time-domain features is shown in Table \@ref(tab:timeSummary) below:

```{r timeSummary, echo = FALSE, warning = FALSE, message = FALSE, results='asis'}

df_time_summaries %>%
  filter(statistic != "p.val") %>%
  filter(!str_detect(statistic, "control|episode")) %>%
  spread(key = statistic, value = value) %>%
  select(variable, n, mean, sd) %>% 
  kable(caption = '(ref:timeSummary)') %>%
  kable_styling()
  
```

Using a Two *t* permutation test run between episodes and controls, none of the time-domain variables were found to be significantly different, shown in Table \@ref(tab:timeComparison).

(ref:timeComparison) Between-Groups Permutation *t*-test of Time Domain Features

(ref:timeComparisonPlot) Between-Groups Permutation *t*-test of Time Domain Features


```{r timeComparison, echo = FALSE, warning = FALSE, message = FALSE}
df_time_summaries %>%
  filter(str_detect(statistic, "control|episode|p.val")) %>%
  spread(key = statistic, value = value) %>%
  select(-p.val, everything()) %>%
  kable(digits=2, caption = '(ref:timeComparison)') %>%
  kable_styling()
```

```{r timeComparisonPlot, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = '(ref:timeComparisonPlot)', fig.width=9, fig.asp=1}
df_time_summaries %>%
  filter(str_detect(statistic, "control|episode|p.val")) %>%
  spread(key = statistic, value = value) %>%
  select(-p.val, everything()) %>%
  gather("Group", "Mean", mean.control:mean.episode) %>%
  permutation_plot(., tip = 0.01)+
    labs(caption = expression(~italic(p)~"-values for permutation "~italic(t)~"-test with 10,000 permutations shown"))
```

(ref:freqSummary) Summary of Features in the Frequency Domain

A similar approach was taken to analyze the frequency domain. Table \@ref(tab:freqSummary) below outlines the mean values of features:

```{r freqSummary, echo = FALSE, warning = FALSE, message = FALSE}
order = c("Avg_HR", "Avg_niHR", "Start_niHR", "End_niHR",
          paste0("HF_", 1:6),
          paste0("LF_", 1:6),
          paste0("LFHF_", 1:6))
df_freq_summaries %>%
  filter(statistic != "p.val") %>%
  filter(!str_detect(statistic, "control|episode")) %>%
  spread(key = statistic, value = value) %>%
  select(variable, n, mean, sd) %>%
  slice(match(order, variable)) %>%
  kable(digits=2, caption = '(ref:freqSummary)') %>%
  kable_styling() %>%
  kableExtra::group_rows("Heart Rate", 1, 4) %>%
  kableExtra::group_rows("High Frequency", 5, 10) %>%
  kableExtra::group_rows("Low Frequency", 11, 16) %>%
  kableExtra::group_rows("LF-HF Ratio", 17, 22)
```

(ref:freqComparison) Between-Groups Permutation *t*-test of Frequency Domain Features

(ref:freqComparisonPlot) Between-Groups Permutation *t*-test of Frequency Domain Features: a) Heart Rate Features; b) High Frequency Features; c) Low Frequency Features d) Low Frequency-High Frequency Ratio Features

Using the same Two-*t* permutation approach, we found signficant differences in means for Average Heart Rate, Average non-interpolated Heart Rate, Ending non-interpolated Heart Rate, and the LF-HF ratio in the third window, shown in Table \@ref(tab:freqComparison)
```{r freqComparison, echo = FALSE, warning = FALSE, message = FALSE}
df_freq_summaries %>%
  filter(str_detect(statistic, "control|episode|p.val")) %>%
  spread(key = statistic, value = value) %>%
  select(-p.val, everything()) %>%
  slice(match(order, variable)) %>%
  kable(digits=2, caption = '(ref:freqComparison)') %>%
  kable_styling() %>%
  kableExtra::group_rows("Heart Rate", 1, 4) %>%
  kableExtra::group_rows("High Frequency", 5, 10) %>%
  kableExtra::group_rows("Low Frequency", 11, 16) %>%
  kableExtra::group_rows("LF-HF Ratio", 17, 22)
```


```{r freqComparisonPlot, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = '(ref:freqComparisonPlot)', fig.width=9, fig.asp=1}

faceted <- df_freq_summaries %>%
  filter(str_detect(statistic, "control|episode|p.val")) %>%
  spread(key = statistic, value = value) %>%
  select(-p.val, everything()) %>%
  gather("Group", "Mean", mean.control:mean.episode) %>%
  mutate(facet = case_when(
    str_detect(variable, "^HF_.*") ~ "High_Frequency",
    str_detect(variable, "^LF_.*") ~ "Low_Frequency",
    str_detect(variable, "^LFHF_.*") ~ "LF-HF Ratio",
    str_detect(variable, "HR") ~ "Heart Rate"
    )
  ) %>%
  nest(-facet)
plots <- pmap(list(df = faceted$data, 
             height = c(1.1, 1.1, 1.1, 1.1),
             tip = c(0.3, 0.05, 0.1, 0.08)),
        permutation_plot)

cowplot::plot_grid(plotlist = plots, labels = paste0(letters[1:4], ")"))
```

## Machine Learning

```{r ml-functions, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE}
modelfit <- function(data){
  
  train <- data$train
  test <- data$test
  # fit the model on the training set
  fit <- train(Y ~ ., data = train, method="svmPoly")
  
  # predict on the test set
  yhat = predict(fit, newdata = select(test, -Y))
  
  # evaluate test accuracy
  conf <- caret::confusionMatrix(yhat, test$Y)
  result <- c(conf$overall[1], conf$byClass[1:2]) #<-can change threshold if you want
  result["auc"] <- auc(test$Y, yhat)
  
  return(result)
  
}

perturb_model_fit <- function(data){
  
  train <- data$train
  test <- data$test
  
  # fit the model on the training set
  invisible(capture.output(fit <- train(Y ~ ., data = train, method="svmPoly", trControl = trainControl(classProbs = TRUE))))
  # get these fitted probabilities
  y = predict(fit, newdata = select(train, -Y), type = "prob") %>%
    rownames_to_column()
  
  # perturb a column from the training set and get the new probabilities
  result <- list(Control = y)
  
  for(c in 2:ncol(train)){
    
    col <- names(train)[c]
    temp <- train
    temp[, col] <- temp[, col] + 1
    result[[col]] <- predict(fit, newdata = select(temp, -Y), type = "prob") %>%
      rownames_to_column()
    
  }
  
  # tidy
  bound <- bind_rows(result, .id='Perturbed_Feature') %>%
    mutate(rowname = as.numeric(rowname)) %>%
    select(-Control) %>% 
    spread(key = "Perturbed_Feature", value = Episode) %>%
    as_tibble() %>%
    bind_cols(Y = train$Y)
  
  return(bound)
  
}

train_test <- function(dataset, folder, print = FALSE){
  
  # issue here with namespace and "data" variable reference
  data <- dataset[-folder, ]
  mytest <- dataset[folder, ]
  
  # generate a balanced training set
  train <- ovun.sample(
    Y ~ .,
    data=data,
    method = "both",
    p = 0.6,
    seed = 1342
  )$data
  
  train <- as_tibble(train) %>%
    droplevels()
  test <- as_tibble(mytest) %>%
    droplevels()
  
  if(print){
    print("Training set:")
    print(train)
    print(table(train$Y))
    print("Testing set:")
    print(test)
    print(table(test$Y))
  }
  
  return(list(train = train, test = test))
  
}

# get variable importance by looping over the columns, leave-one-out for each model
leave_one_out_auc <- function(df, col){
  
  df_reduced <- df %>%
    select(-!!col)
  set.seed(9)
  nfolds <- 4
  subdata <- createFolds(df_reduced$Y, nfolds)
  
  temp1 <- train_test(df_reduced, subdata$Fold1) %>%
    modelfit()
  temp2 <- train_test(df_reduced, subdata$Fold2) %>%
    modelfit()
  temp3 <- train_test(df_reduced, subdata$Fold3) %>%
    modelfit()
  temp4 <- train_test(df_reduced, subdata$Fold4)%>%
    modelfit()

    
  auc <- colMeans(rbind(temp1['auc'],temp2['auc'], temp3['auc'], temp4['auc'])) %>%
    t() %>%
    data.frame(auc = ., variable = names(df)[col])
  return(auc)
}
```

```{r ml-datasets, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE}
df_time_ml <- read.csv(here('data', 'Preprocessing_data_outputs', 'Paper', 'data_out.csv'))%>%
  # use params threshold = 250, windows = 2
  filter(threshold == 250 & winds == 2)%>%
  select(-winds, - threshold, -index) %>%
  filter(complete.cases(.)) %>%
  filter(!((Stress>=5) & (Y == "Control")))

df_time_ml <- df_time_ml %>%
  mutate(ID = as.factor(ID)) %>%
  group_by(ID) %>%
  mutate_at(vars(SDNN:HRVi), scale) %>%
  ungroup() %>%
  select(Y:HRVi) %>%
  filter(complete.cases(.))

df_freq_ml <- read.csv(here('data', 'Preprocessing_data_outputs', 'Paper', 'data_out_20181113.csv'))%>%
  # use params threshold = 250, windows = 2
  select(-c(winds, threshold, index, when, Event)) %>%
  select(Y, ID, Stress, Avg_niHR:LF_6) %>%
  filter(complete.cases(.)) %>%
  filter(!(Stress >= 5 & Y == "Control"))
  

df_freq_ml <- df_freq_ml %>%
  mutate(ID = as.factor(ID)) %>%
  group_by(ID) %>%
  mutate_at(vars(Avg_niHR:LF_6), scale) %>%
  ungroup() %>%
  select(Y, Avg_niHR:LF_6) %>%
  filter(complete.cases(.))
```

```{r ml-time, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE}
set.seed(9)
nfolds <- 4
subdata<-createFolds(df_time_ml$Y, nfolds)
t1_z <- train_test(df_time_ml, subdata$Fold1) %>%
  modelfit()
t2_z <- train_test(df_time_ml, subdata$Fold2) %>%
  modelfit()
t3_z <- train_test(df_time_ml, subdata$Fold3) %>%
  modelfit()
t4_z <- train_test(df_time_ml, subdata$Fold4) %>%
  modelfit()
results_time <- colMeans(rbind(t1_z, t2_z, t3_z, t4_z))
```

```{r auc-importance-time, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE}
auc_comparison_time <- list()

for(c in 2:ncol(df_time_ml)){
  auc_comparison_time <- leave_one_out_auc(df_time_ml, c) %>%
    rbind(auc_comparison_time)
}

auc_time <- auc_comparison_time %>%
  mutate(Reduction_AUC = results_time['auc'] - auc) %>%
  mutate(Reduction_AUC = rescale(Reduction_AUC, c(0,1))) %>%
  arrange(-Reduction_AUC)
```

```{r perturbations-time, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE}
set.seed(9)
nfolds <- 4
subdata<-createFolds(df_time_ml$Y, nfolds)

perturbed_time_1 <- train_test(df_time_ml, subdata$Fold1) %>%     # split train and test
  perturb_model_fit() %>%                                   # fit model and perturb each column
  mutate_at(                                                # tidy to get differences
    .vars = vars(-rowname, -Y, -Control),
    .funs = list(Delta = ~. - Control))# %>%
  #select(Y, contains("Delta"))

perturbed_time_2 <- train_test(df_time_ml, subdata$Fold2) %>%     # split train and test
  perturb_model_fit() %>%                                   # fit model and perturb each column
  mutate_at(                                                # tidy to get differences
    .vars = vars(-rowname, -Y, -Control),
    .funs = list(Delta = ~. - Control)) #%>%
  #select(Y, contains("Delta"))

perturbed_time_3 <- train_test(df_time_ml, subdata$Fold3) %>%     # split train and test
  perturb_model_fit() %>%                                   # fit model and perturb each column
  mutate_at(                                                # tidy to get differences
    .vars = vars(-rowname, -Y, -Control),
    .funs = list(Delta = ~. - Control)) #%>%
  #select(Y, contains("Delta"))

perturbed_time_4 <- train_test(df_time_ml, subdata$Fold4) %>%     # split train and test
  perturb_model_fit() %>%                                   # fit model and perturb each column
  mutate_at(                                                # tidy to get differences
    .vars = vars(-rowname, -Y, -Control),
    .funs = list(Delta = ~. - Control)) #%>%
  #select(Y, contains("Delta"))

```

```{r ml-freq, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE}
set.seed(9)
nfolds <- 4
subdata<-createFolds(df_freq_ml$Y, nfolds)
f1_z <- train_test(df_freq_ml, subdata$Fold1) %>%
  modelfit()
f2_z <- train_test(df_freq_ml, subdata$Fold2) %>%
  modelfit()
f3_z <- train_test(df_freq_ml, subdata$Fold3) %>%
  modelfit()
f4_z <- train_test(df_freq_ml, subdata$Fold4) %>%
  modelfit()
results_freq <- colMeans(rbind(f1_z, f2_z, f3_z, f4_z))
```

```{r auc-importance-freq, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE}
auc_comparison_freq <- list()

for(c in 2:ncol(df_freq_ml)){
  auc_comparison_freq <- leave_one_out_auc(df_freq_ml, c) %>%
    rbind(auc_comparison_freq)
}

auc_freq <- auc_comparison_freq %>%
  mutate(Reduction_AUC = results_freq['auc'] - auc) %>%
  mutate(Reduction_AUC = rescale(Reduction_AUC, c(0,1))) %>%
  arrange(-Reduction_AUC)
```

```{r perturbations-freq, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE}
set.seed(9)
nfolds <- 4
subdata<-createFolds(df_freq_ml$Y, nfolds)

perturbed_freq_1 <- train_test(df_freq_ml, subdata$Fold1) %>%     # split train and test
  perturb_model_fit() %>%                                   # fit model and perturb each column
  mutate_at(                                                # tidy to get differences
    .vars = vars(-rowname, -Y, -Control),
    .funs = list(Delta = ~. - Control)) #%>%
  #select(Y, contains("Delta"))

perturbed_freq_2 <- train_test(df_freq_ml, subdata$Fold2) %>%     # split train and test
  perturb_model_fit() %>%                                   # fit model and perturb each column
  mutate_at(                                                # tidy to get differences
    .vars = vars(-rowname, -Y, -Control),
    .funs = list(Delta = ~. - Control)) #%>%
  #select(Y, contains("Delta"))

perturbed_freq_3 <- train_test(df_freq_ml, subdata$Fold3) %>%     # split train and test
  perturb_model_fit() %>%                                   # fit model and perturb each column
  mutate_at(                                                # tidy to get differences
    .vars = vars(-rowname, -Y, -Control),
    .funs = list(Delta = ~. - Control)) #%>%
  #select(Y, contains("Delta"))

perturbed_freq_4 <- train_test(df_freq_ml, subdata$Fold4) %>%     # split train and test
  perturb_model_fit() %>%                                   # fit model and perturb each column
  mutate_at(                                                # tidy to get differences
    .vars = vars(-rowname, -Y, -Control),
    .funs = list(Delta = ~. - Control)) #%>%
  #select(Y, contains("Delta"))

```

```{r gather-importance, echo = FALSE, warning = FALSE, message = FALSE}
time_domain_deltas <- bind_rows(perturbed_time_1, perturbed_time_2, perturbed_time_3, perturbed_time_4) %>%
  group_by(Y) %>%
  summarise_if(is.numeric, mean) %>%
  select(-rowname) %>%
  select(Y, contains("_Delta")) %>%
  gather("variable", "Delta_Probability", -Y) %>%
  mutate(variable = str_replace(variable, pattern = "_Delta", replacement = ""))

freq_domain_deltas <- bind_rows(perturbed_freq_1, perturbed_freq_2, perturbed_freq_3, perturbed_freq_4) %>%
  group_by(Y) %>%
  summarise_if(is.numeric, mean) %>%
  select(-rowname) %>%
  select(Y, contains("_Delta")) %>%
  gather("variable", "Delta_Probability", -Y) %>%
  mutate(variable = str_replace(variable, pattern = "_Delta", replacement = ""))
```

(ref:ml-metrics) Machine Learning Evaluation Metrics

Machine learning models were implemented using time domain and frequency domain features separately. In order to run machine learning prediction of emotional eating episodes, observations with complete data for all features in the time or frequency domain were used, data within each participant were scaled and centered, and observations were randomly upsampled (from episodes) or downsampled (from controls) to balance the number of observations and controls. SVM models were fit iteratively using 3/4's of the data, and evaluated on the remaining 1/4. Figure \@ref(fig:ml-metrics) show the mean accuracy, sensitivity, and specificity of the SVM across these four folds.

```{r ml-metrics, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = '(ref:ml-metrics)', fig.width=9, fig.asp=1}
ml_time <- results_time %>%
  enframe(name = "Metric", value = "Value") %>%
  mutate(Metric = ifelse(Metric == "auc", "AUC", Metric),
         Domain = "Time")

ml_freq <- results_freq %>%
  enframe(name = "Metric", value = "Value") %>%
  mutate(Metric = ifelse(Metric == "auc", "AUC", Metric),
         Domain = "Frequency")

bind_rows(ml_time, ml_freq) %>%
  ggplot(aes(x=Metric, y=Value, fill=Domain))+
  geom_col(position = "dodge") +
  geom_text(aes(label=formatC(Value, 2), y = Value + 0.025), position = position_dodge(width=0.9), vjust=-0.25) +
  theme_minimal() +
  scale_fill_viridis_d() +
  theme(text = element_text(size=15, family = "Times"))
```


(ref:varImportance-time) Pseudo-Feature Importance by Removing & Perturbing Each Feature: Time Domain

(ref:varImportance-freq) Pseudo-Feature Importance by Removing & Perturbing Each Feature: Frequency Domain

To interpret the feature importance in each of these models, ROC curve analysis was conducted on each feature on the model as recommended by Khun @R-caret, by systemmatically removing each variable from the model and comparing the achieved Area Under the Curve (AUC) against that of the full model. In order to assess whether or not these features discriminate well between episodes and controls, models were fitted on the original data and the fitted values were perturbed for each variable. The probabilities of predictions were extracted from each perturbed model and compared to the probabilities of the original model, to understand how increasing values of the features increased or decreased the likelihood of an eating episode. Figures \@ref(fig:varImportance-time) and \@ref(fig:varImportance-freq) show the results of this analysis.

```{r varImportance-time, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = '(ref:varImportance-time)', fig.width=9, fig.asp=1}
time_domain_deltas %>% 
  group_by(variable) %>%
  summarise(Delta_Probability = mean(Delta_Probability)) %>%
  right_join(auc_time, by = "variable") %>%
  as_tibble() %>%
  mutate(
    Feature = fct_reorder(variable, Reduction_AUC, .desc = TRUE),
    Delta_Probability = as.factor(ifelse(Delta_Probability >= 0, "Increase", "Decrease"))
  ) %>%
  select(-variable) %>%
  ggplot(aes(x = Feature, y = Reduction_AUC))+
    geom_segment(
      aes(
        y = 0,
        x = Feature, 
        yend = Reduction_AUC, 
        xend = Feature
      ), 
      color = "black"
    ) +
    geom_point(aes(colour = Delta_Probability), size = 8) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1),
      text = element_text(size=15, family = "Times"),
      legend.position = "bottom"
    ) +
    labs(
      x = "Feature",
      y = "Decrease in Model AUC When Feature Removed"
    ) +
  scale_color_viridis_d(name = "Mean Change in Probability of \"Episode\" Prediction when Feature Perturbed")
```

In the time domain, the most important feature by measure of decrease in model AUC was *SDANN*, followed by *SDNN* and *MADRR*. Increasing values in *SDANN* by 1 unit tended to decrease the probability of observations being predicted as episode, suggesting that higher levels of *SDANN* decrease the likelihood of an eating episode. This same inference can be made of *MADRR*. In the case of *SDNN*, a 1 unit increase in values of this feature increased the probability of observations being predicted as episodes.

```{r varImportance-freq, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = '(ref:varImportance-freq)', fig.width=9, fig.asp=1}
freq_domain_deltas %>% 
  group_by(variable) %>%
  summarise(Delta_Probability = mean(Delta_Probability)) %>%
  right_join(auc_freq, by = "variable") %>%
  as_tibble() %>%
  mutate(
    Feature = fct_reorder(variable, Reduction_AUC, .desc = TRUE),
    Delta_Probability = as.factor(ifelse(Delta_Probability >= 0, "Increase", "Decrease"))
  ) %>%
  select(-variable) %>%
  ggplot(aes(x = Feature, y = Reduction_AUC))+
    geom_segment(
      aes(
        y = 0,
        x = Feature, 
        yend = Reduction_AUC, 
        xend = Feature
      ), 
      color = "black"
    ) +
    geom_point(aes(colour = Delta_Probability), size = 8) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1),
      text = element_text(size=15, family = "Times"),
      legend.position = "bottom"
    ) +
    #facet_grid(Y~.) +
    labs(
      x = "Feature",
      y = "Decrease in Model AUC When Feature Removed"
    ) +
  scale_color_viridis_d(name = "Mean Change in Probability of \"Episode\" Prediction when Feature Perturbed")
```

In the frequency domain, the most important features by measure of decrease in model AUC were the High Frequency windows $HF_2$, $HF_6$, and $HF_3$. Increasing values in $HF_2$ by 1 unit tended to decrease the probability of observations being predicted as episode, suggesting that stronger signals in the high frequency band at this time in the window decrease the likelihood of an eating episode. This inference is the opposite, however, for $HF_6$ and $HF_3$, which show that increasing these variables' values by one unit tends to increase the likelihood of an eating episode. Interestingly, while the heart rate variables *Avg_HR*, *Avg_niHR*, and *End_niHR* had significantly different means, their affect on the achieved AUC was relatively minimal, indicating they had very small feature importance for this model.

(ref:highfreq-timeseries) Time Series of High Frequency Band

To better interpret how the signal in the high frequency band of heart rate varies through the 30-minute window, we plot these values in Figure \@ref(fig:highfreq-timeseries) below:

```{r highfreq-timeseries, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = '(ref:highfreq-timeseries)', fig.width=9, fig.asp=1}
df_freq_ml %>%
  gather('variable', 'value', HF_1:HF_6) %>%
  ggplot(aes(x=variable, y=value, colour=Y)) +
  geom_jitter(alpha = 0.6, width = 0.15) +
  stat_smooth(aes(group = Y), method = "loess") +
  labs(x = "Frequency Band Window", y = "Z-Score") +
  theme_minimal() +
  scale_color_viridis_d()
```

The visualisation shows that at the second window, $HF_2$, there is an inverse relationship between the trajectories of episodes and controls, which may represent the high variable importance of $HF_2$. $HF_6$ shows a similar inverse trend, as increasing values of this variable are associated with episodes while decreasing values are associated with controls.

# Discussion

A major hurdle to producing interpretable results is the sanity of data obtained from the devices. Despite best efforts, figures \@ref(fig:missingness-time) and \@ref(fig:missingness-freq) illustrate how sparse the data can be and how this affects its overall usefulness in running analyses.The causes for this data sparsity are unclear, and could include reasons such as improper usage or low signal while recording data. The result of this challenge is that derived features are incalculable; for example, time domain feature calculations are strongly dependent on a sliding window that must have within it at least some number of consecutive heart beats, or completeness and consecutiveness of *SDNN*; frequency domain variables are dependent on Fourier transforms which are sensitive to small and variations in wave frequencies. Nevertheless, by following proper data sanity checks and procedures provided in analyses packages and in the literature, it's still possible to extract useful information from these data.

Although no features in the time domain were significantly different between episode and control observations when tested, it's worth mentioning that the machine learning model was still able to achieve decent classification accuracy, sensitivity, and specificity using these features. The most impactful features in this model were *rMSSD* (Root Mean Square of Successive Differences); *SDSD* (Standard Deviation of Successive Differences of inter-beat intervals); and *MADRR* (Median of the Absolute values of the successive Differences between the inter-beat intervals). However, the frequency domain achieved superior classification accuracy in comparison to the time domain, with mean accuracy of `r 100*round(results_freq['Accuracy'], 3)`%, sensitivity of `r 100*round(results_freq['Sensitivity'], 3)`%, and specificity of `r 100*round(results_freq['Specificity'], 3)`%. For this model, the greatest variable importance was for $HF_1$, $LF_5$, $LF_6$, $LF_1$, and $LF_2$. This may reflect a tendency of heart rate to change most noticeably in the low frequency power band, in the moments leading up to an eating episode.

***

